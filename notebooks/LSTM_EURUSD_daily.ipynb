{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7758dbfc-5944-42a7-82d6-a95ad10ab9de",
   "metadata": {},
   "source": [
    "# Training of the 3 most optimal LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36abdc99-960f-4888-ae0a-e98144d41564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 12:45:54.044272: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-24 12:45:54.046860: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-24 12:45:54.054047: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-24 12:45:54.065336: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-24 12:45:54.068697: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-24 12:45:54.078377: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-24 12:45:54.777307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from tensorflow.keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c350fd-48b1-4c68-b0fc-ccff99ffc678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>MA20</th>\n",
       "      <th>MA50</th>\n",
       "      <th>Rolling_STD</th>\n",
       "      <th>Daily_Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>...</th>\n",
       "      <th>High_Low_Diff</th>\n",
       "      <th>Volatility_Price_Ratio</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Rolling_Return_5d</th>\n",
       "      <th>MA20_MA50_Interaction</th>\n",
       "      <th>Close_Volatility_Interaction</th>\n",
       "      <th>EMA20</th>\n",
       "      <th>EMA50</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-11-23</th>\n",
       "      <td>2.191889</td>\n",
       "      <td>2.257424</td>\n",
       "      <td>2.252358</td>\n",
       "      <td>2.192606</td>\n",
       "      <td>2.266625</td>\n",
       "      <td>1.613936</td>\n",
       "      <td>-0.412957</td>\n",
       "      <td>0.954561</td>\n",
       "      <td>2.01357</td>\n",
       "      <td>2.215342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160033</td>\n",
       "      <td>-0.556635</td>\n",
       "      <td>0.550805</td>\n",
       "      <td>1.092093</td>\n",
       "      <td>2.015158</td>\n",
       "      <td>2.658475</td>\n",
       "      <td>2.219578</td>\n",
       "      <td>2.257584</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.093239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-24</th>\n",
       "      <td>2.308272</td>\n",
       "      <td>2.330381</td>\n",
       "      <td>2.312030</td>\n",
       "      <td>2.302185</td>\n",
       "      <td>2.266625</td>\n",
       "      <td>1.613936</td>\n",
       "      <td>-0.412957</td>\n",
       "      <td>0.954561</td>\n",
       "      <td>2.01357</td>\n",
       "      <td>2.215342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022916</td>\n",
       "      <td>-0.563156</td>\n",
       "      <td>0.550805</td>\n",
       "      <td>1.092093</td>\n",
       "      <td>2.015158</td>\n",
       "      <td>2.689204</td>\n",
       "      <td>2.230200</td>\n",
       "      <td>2.262066</td>\n",
       "      <td>0.128314</td>\n",
       "      <td>0.100489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-25</th>\n",
       "      <td>2.389062</td>\n",
       "      <td>2.416758</td>\n",
       "      <td>2.384088</td>\n",
       "      <td>2.391431</td>\n",
       "      <td>2.266625</td>\n",
       "      <td>1.613936</td>\n",
       "      <td>-0.412957</td>\n",
       "      <td>0.775757</td>\n",
       "      <td>2.01357</td>\n",
       "      <td>2.215342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219317</td>\n",
       "      <td>-0.568423</td>\n",
       "      <td>0.550805</td>\n",
       "      <td>1.092093</td>\n",
       "      <td>2.015158</td>\n",
       "      <td>2.714231</td>\n",
       "      <td>2.248461</td>\n",
       "      <td>2.270022</td>\n",
       "      <td>0.187758</td>\n",
       "      <td>0.118470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-26</th>\n",
       "      <td>2.439155</td>\n",
       "      <td>2.409953</td>\n",
       "      <td>2.424995</td>\n",
       "      <td>2.439066</td>\n",
       "      <td>2.266625</td>\n",
       "      <td>1.613936</td>\n",
       "      <td>-0.412957</td>\n",
       "      <td>0.417363</td>\n",
       "      <td>2.01357</td>\n",
       "      <td>2.215342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464050</td>\n",
       "      <td>-0.571217</td>\n",
       "      <td>0.550805</td>\n",
       "      <td>1.092093</td>\n",
       "      <td>2.015158</td>\n",
       "      <td>2.727590</td>\n",
       "      <td>2.269600</td>\n",
       "      <td>2.279614</td>\n",
       "      <td>0.254458</td>\n",
       "      <td>0.146521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-27</th>\n",
       "      <td>2.350267</td>\n",
       "      <td>2.350416</td>\n",
       "      <td>2.359130</td>\n",
       "      <td>2.356410</td>\n",
       "      <td>2.266625</td>\n",
       "      <td>1.613936</td>\n",
       "      <td>-0.412957</td>\n",
       "      <td>-0.694317</td>\n",
       "      <td>2.01357</td>\n",
       "      <td>2.215342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367195</td>\n",
       "      <td>-0.566361</td>\n",
       "      <td>0.550805</td>\n",
       "      <td>1.092093</td>\n",
       "      <td>2.015158</td>\n",
       "      <td>2.704410</td>\n",
       "      <td>2.280713</td>\n",
       "      <td>2.285450</td>\n",
       "      <td>0.285147</td>\n",
       "      <td>0.175250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close      MA20      MA50  \\\n",
       "date                                                                     \n",
       "2014-11-23  2.191889  2.257424  2.252358  2.192606  2.266625  1.613936   \n",
       "2014-11-24  2.308272  2.330381  2.312030  2.302185  2.266625  1.613936   \n",
       "2014-11-25  2.389062  2.416758  2.384088  2.391431  2.266625  1.613936   \n",
       "2014-11-26  2.439155  2.409953  2.424995  2.439066  2.266625  1.613936   \n",
       "2014-11-27  2.350267  2.350416  2.359130  2.356410  2.266625  1.613936   \n",
       "\n",
       "            Rolling_STD  Daily_Return  Volatility  Upper_Band  ...  \\\n",
       "date                                                           ...   \n",
       "2014-11-23    -0.412957      0.954561     2.01357    2.215342  ...   \n",
       "2014-11-24    -0.412957      0.954561     2.01357    2.215342  ...   \n",
       "2014-11-25    -0.412957      0.775757     2.01357    2.215342  ...   \n",
       "2014-11-26    -0.412957      0.417363     2.01357    2.215342  ...   \n",
       "2014-11-27    -0.412957     -0.694317     2.01357    2.215342  ...   \n",
       "\n",
       "            High_Low_Diff  Volatility_Price_Ratio  Momentum  \\\n",
       "date                                                          \n",
       "2014-11-23      -0.160033               -0.556635  0.550805   \n",
       "2014-11-24       0.022916               -0.563156  0.550805   \n",
       "2014-11-25       0.219317               -0.568423  0.550805   \n",
       "2014-11-26      -0.464050               -0.571217  0.550805   \n",
       "2014-11-27      -0.367195               -0.566361  0.550805   \n",
       "\n",
       "            Rolling_Return_5d  MA20_MA50_Interaction  \\\n",
       "date                                                   \n",
       "2014-11-23           1.092093               2.015158   \n",
       "2014-11-24           1.092093               2.015158   \n",
       "2014-11-25           1.092093               2.015158   \n",
       "2014-11-26           1.092093               2.015158   \n",
       "2014-11-27           1.092093               2.015158   \n",
       "\n",
       "            Close_Volatility_Interaction     EMA20     EMA50      MACD  \\\n",
       "date                                                                     \n",
       "2014-11-23                      2.658475  2.219578  2.257584  0.092931   \n",
       "2014-11-24                      2.689204  2.230200  2.262066  0.128314   \n",
       "2014-11-25                      2.714231  2.248461  2.270022  0.187758   \n",
       "2014-11-26                      2.727590  2.269600  2.279614  0.254458   \n",
       "2014-11-27                      2.704410  2.280713  2.285450  0.285147   \n",
       "\n",
       "            Signal_Line  \n",
       "date                     \n",
       "2014-11-23     0.093239  \n",
       "2014-11-24     0.100489  \n",
       "2014-11-25     0.118470  \n",
       "2014-11-26     0.146521  \n",
       "2014-11-27     0.175250  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/processed/scaled_EURUSD_daily.csv\", index_col=0, parse_dates=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec9c9f5-36c3-411a-bde8-b6338e035d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2608 entries, 2014-11-23 to 2024-11-22\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Open                          2608 non-null   float64\n",
      " 1   High                          2608 non-null   float64\n",
      " 2   Low                           2608 non-null   float64\n",
      " 3   Close                         2608 non-null   float64\n",
      " 4   MA20                          2608 non-null   float64\n",
      " 5   MA50                          2608 non-null   float64\n",
      " 6   Rolling_STD                   2608 non-null   float64\n",
      " 7   Daily_Return                  2608 non-null   float64\n",
      " 8   Volatility                    2608 non-null   float64\n",
      " 9   Upper_Band                    2608 non-null   float64\n",
      " 10  Lower_Band                    2608 non-null   float64\n",
      " 11  Bollinger_Bandwidth           2608 non-null   float64\n",
      " 12  Lag1_Close                    2608 non-null   float64\n",
      " 13  Lag2_Close                    2608 non-null   float64\n",
      " 14  MA_Crossover                  2608 non-null   float64\n",
      " 15  Crossed_MA20                  2608 non-null   float64\n",
      " 16  Crossed_MA50                  2608 non-null   float64\n",
      " 17  Rate_of_Change                2608 non-null   float64\n",
      " 18  Daily_Range                   2608 non-null   float64\n",
      " 19  Weekly_Range                  2608 non-null   float64\n",
      " 20  %B                            2608 non-null   float64\n",
      " 21  RSI                           2608 non-null   float64\n",
      " 22  Close_Open_Diff               2608 non-null   float64\n",
      " 23  High_Low_Diff                 2608 non-null   float64\n",
      " 24  Volatility_Price_Ratio        2608 non-null   float64\n",
      " 25  Momentum                      2608 non-null   float64\n",
      " 26  Rolling_Return_5d             2608 non-null   float64\n",
      " 27  MA20_MA50_Interaction         2608 non-null   float64\n",
      " 28  Close_Volatility_Interaction  2608 non-null   float64\n",
      " 29  EMA20                         2608 non-null   float64\n",
      " 30  EMA50                         2608 non-null   float64\n",
      " 31  MACD                          2608 non-null   float64\n",
      " 32  Signal_Line                   2608 non-null   float64\n",
      "dtypes: float64(33)\n",
      "memory usage: 692.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d579f-c0ae-4cc4-b706-eac393ff786b",
   "metadata": {},
   "source": [
    "----\n",
    "## Split data into Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09a62ab-a45e-4530-bbed-20e797614837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (2086, 3), (2086,)\n",
      "Testing set: (522, 3), (522,)\n"
     ]
    }
   ],
   "source": [
    "target = 'Close'\n",
    "# Use only the \"optimal features\" selected from Random Forrest feature selection.\n",
    "selected_features = ['Open', 'High', 'Low']\n",
    "\n",
    "train_size = int(len(data) * 0.8)\n",
    "\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "\n",
    "X_train, y_train = train_data[selected_features], train_data[target]\n",
    "X_test, y_test = test_data[selected_features], test_data[target]\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff4d02-e6b8-49cc-b2b1-b89b88b5c304",
   "metadata": {},
   "source": [
    "---\n",
    "## LSTM Architecture with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c636dd7a-7b66-470d-9b9e-20b740174ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target, window_size):\n",
    "    \"\"\"\n",
    "    Converts data into sliding window sequences for LSTM.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input features.\n",
    "        target (pd.Series): Target values (e.g., 'Close').\n",
    "        window_size (int): Number of past observations in each sequence.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X, y) where X is the feature tensor and y is the target vector.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data.iloc[i:i + window_size].values)\n",
    "        y.append(target.iloc[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#Set Window size and create sequences\n",
    "window_size = 50\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(\n",
    "    pd.DataFrame(X_train, columns=selected_features),\n",
    "    y_train,\n",
    "    window_size\n",
    ")\n",
    "X_test_seq, y_test_seq = create_sequences(\n",
    "    pd.DataFrame(X_test, columns=selected_features),\n",
    "    y_test,\n",
    "    window_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60c0a6c-7043-4f02-8b35-e01d3ef76d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(LSTM(\n",
    "            units=hp.Int(f\"units_{i}\", min_value=32, max_value=128, step=32),\n",
    "            return_sequences=(i < hp.Int(\"num_layers\", 1, 3) - 1)\n",
    "        ))\n",
    "        model.add(Dropout(hp.Float(f\"dropout_{i}\", 0.1, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6653bb-7c83-421c-ab3f-1b570c248cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 48s]\n",
      "val_loss: 0.003066711826249957\n",
      "\n",
      "Best val_loss So Far: 0.002484046504832804\n",
      "Total elapsed time: 00h 20m 26s\n",
      "Top 1 Hyperparameters: {'num_layers': 1, 'units_0': 128, 'dropout_0': 0.1, 'lr': 0.0058263756897235135, 'units_1': 64, 'dropout_1': 0.4, 'units_2': 64, 'dropout_2': 0.1}\n",
      "Top 2 Hyperparameters: {'num_layers': 1, 'units_0': 64, 'dropout_0': 0.2, 'lr': 0.006882586554868881, 'units_1': 128, 'dropout_1': 0.30000000000000004, 'units_2': 96, 'dropout_2': 0.5}\n",
      "Top 3 Hyperparameters: {'num_layers': 2, 'units_0': 32, 'dropout_0': 0.1, 'lr': 0.004114773318984142, 'units_1': 96, 'dropout_1': 0.1, 'units_2': 64, 'dropout_2': 0.30000000000000004}\n"
     ]
    }
   ],
   "source": [
    "#Find best Hyperparameters\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"hyperparam_tuning\",\n",
    "    project_name=\"lstm_close_price_with_window\"\n",
    ")\n",
    "tuner.search(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=3)\n",
    "for i, hp in enumerate(best_hps):\n",
    "    print(f\"Top {i+1} Hyperparameters: {hp.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22092c79-4836-4ca4-8281-b3a8248858a1",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4331badd-bc75-43ab-bcdb-3da5f996e51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Model 1...\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Training and evaluating Model 2...\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Training and evaluating Model 3...\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "     Model  Train_MSE  Test_MSE  Train_R²   Test_R²\n",
      "0  Model_1   0.005812  0.003992  0.994324  0.953978\n",
      "1  Model_2   0.006812  0.004811  0.993347  0.944529\n",
      "2  Model_3   0.005928  0.002840  0.994211  0.967252\n"
     ]
    }
   ],
   "source": [
    "def build_and_train_model(hp, X_train_seq, y_train_seq, X_test_seq, y_test_seq):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add input layer\n",
    "    model.add(Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "\n",
    "    # Add LSTM layers based on hyperparameters\n",
    "    for i in range(hp['num_layers']):\n",
    "        return_sequences = i < hp['num_layers'] - 1  # True for all but the last layer\n",
    "        model.add(LSTM(units=hp[f'units_{i}'], return_sequences=return_sequences))\n",
    "        model.add(Dropout(rate=hp[f'dropout_{i}']))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp['lr']),\n",
    "        loss=\"mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_seq, y_train_seq, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_seq)\n",
    "    y_test_pred = model.predict(X_test_seq)\n",
    "\n",
    "    # Metrics\n",
    "    train_mse = mean_squared_error(y_train_seq, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test_seq, y_test_pred)\n",
    "    train_r2 = r2_score(y_train_seq, y_train_pred)\n",
    "    test_r2 = r2_score(y_test_seq, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"train_mse\": train_mse,\n",
    "        \"test_mse\": test_mse,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2\n",
    "    }\n",
    "\n",
    "# Top hyperparameters\n",
    "top_hyperparams = [\n",
    "    {'num_layers': 3, 'units_0': 64, 'dropout_0': 0.1, 'lr': 0.007527178255464862,\n",
    "     'units_1': 128, 'dropout_1': 0.1, 'units_2': 32, 'dropout_2': 0.1},\n",
    "    {'num_layers': 2, 'units_0': 64, 'dropout_0': 0.2, 'lr': 0.006641024661942141,\n",
    "     'units_1': 32, 'dropout_1': 0.2, 'units_2': 64, 'dropout_2': 0.1},\n",
    "    {'num_layers': 2, 'units_0': 32, 'dropout_0': 0.3, 'lr': 0.009043644296402382,\n",
    "     'units_1': 64, 'dropout_1': 0.4, 'units_2': 64, 'dropout_2': 0.2}\n",
    "]\n",
    "\n",
    "# Evaluate top 3 models\n",
    "model_results = []\n",
    "for i, hp in enumerate(top_hyperparams, start=1):\n",
    "    print(f\"Training and evaluating Model {i}...\")\n",
    "    result = build_and_train_model(hp, X_train_seq, y_train_seq, X_test_seq, y_test_seq)\n",
    "    model_results.append({\n",
    "        \"Model\": f\"Model_{i}\",\n",
    "        \"Train_MSE\": result[\"train_mse\"],\n",
    "        \"Test_MSE\": result[\"test_mse\"],\n",
    "        \"Train_R²\": result[\"train_r2\"],\n",
    "        \"Test_R²\": result[\"test_r2\"]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(model_results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ad767-f2c3-48cd-b11a-8f12d6688abb",
   "metadata": {},
   "source": [
    "----\n",
    "## Retrain on Full dataset\n",
    "\n",
    "This maximizes the predictive power of these models before testing them on the unseen dataset in the `model_comparison` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34313b1-6f9a-48ea-8759-4c0b6b5afb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (2508, 50, 3), (2508,)\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test sets into a full dataset\n",
    "X_full = np.concatenate([X_train_seq, X_test_seq], axis=0)\n",
    "y_full = np.concatenate([y_train_seq, y_test_seq], axis=0)\n",
    "print(f\"Full dataset shape: {X_full.shape}, {y_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c379d500-db0d-4c2a-8c7c-afe35b3ef615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1 with params: {'num_layers': 3, 'units_0': 64, 'dropout_0': 0.1, 'lr': 0.007527178255464862, 'units_1': 128, 'dropout_1': 0.1, 'units_2': 32, 'dropout_2': 0.1}\n",
      "Epoch 1/20\n",
      "79/79 - 5s - 59ms/step - loss: 0.0854 - mae: 0.2001\n",
      "Epoch 2/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0294 - mae: 0.1283\n",
      "Epoch 3/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0234 - mae: 0.1146\n",
      "Epoch 4/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0182 - mae: 0.0997\n",
      "Epoch 5/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0193 - mae: 0.1026\n",
      "Epoch 6/20\n",
      "79/79 - 3s - 33ms/step - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 7/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0132 - mae: 0.0844\n",
      "Epoch 8/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0133 - mae: 0.0841\n",
      "Epoch 9/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0181 - mae: 0.0989\n",
      "Epoch 10/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0142 - mae: 0.0876\n",
      "Epoch 11/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0153 - mae: 0.0873\n",
      "Epoch 12/20\n",
      "79/79 - 3s - 32ms/step - loss: 0.0148 - mae: 0.0893\n",
      "Model 1 saved as '../models/EURUSD_daily/lstm_model_full_1.keras'.\n",
      "Training Model 2 with params: {'num_layers': 2, 'units_0': 64, 'dropout_0': 0.2, 'lr': 0.006641024661942141, 'units_1': 32, 'dropout_1': 0.2, 'units_2': 64, 'dropout_2': 0.1}\n",
      "Epoch 1/20\n",
      "79/79 - 3s - 33ms/step - loss: 0.0727 - mae: 0.1862\n",
      "Epoch 2/20\n",
      "79/79 - 1s - 15ms/step - loss: 0.0306 - mae: 0.1307\n",
      "Epoch 3/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0286 - mae: 0.1235\n",
      "Epoch 4/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0258 - mae: 0.1165\n",
      "Epoch 5/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0229 - mae: 0.1100\n",
      "Epoch 6/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0224 - mae: 0.1082\n",
      "Epoch 7/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0229 - mae: 0.1077\n",
      "Epoch 8/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0176 - mae: 0.0975\n",
      "Epoch 9/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0188 - mae: 0.0983\n",
      "Epoch 10/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0180 - mae: 0.0955\n",
      "Epoch 11/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0198 - mae: 0.0990\n",
      "Epoch 12/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 13/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0204 - mae: 0.1016\n",
      "Model 2 saved as '../models/EURUSD_daily/lstm_model_full_2.keras'.\n",
      "Training Model 3 with params: {'num_layers': 2, 'units_0': 32, 'dropout_0': 0.30000000000000004, 'lr': 0.009043644296402382, 'units_1': 64, 'dropout_1': 0.4, 'units_2': 64, 'dropout_2': 0.2}\n",
      "Epoch 1/20\n",
      "79/79 - 3s - 33ms/step - loss: 0.0976 - mae: 0.2093\n",
      "Epoch 2/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0475 - mae: 0.1597\n",
      "Epoch 3/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0347 - mae: 0.1375\n",
      "Epoch 4/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0394 - mae: 0.1396\n",
      "Epoch 5/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0337 - mae: 0.1328\n",
      "Epoch 6/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0301 - mae: 0.1225\n",
      "Epoch 7/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0303 - mae: 0.1244\n",
      "Epoch 8/20\n",
      "79/79 - 1s - 15ms/step - loss: 0.0275 - mae: 0.1177\n",
      "Epoch 9/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0303 - mae: 0.1212\n",
      "Epoch 10/20\n",
      "79/79 - 1s - 15ms/step - loss: 0.0271 - mae: 0.1168\n",
      "Epoch 11/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0271 - mae: 0.1170\n",
      "Epoch 12/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0278 - mae: 0.1182\n",
      "Epoch 13/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0303 - mae: 0.1222\n",
      "Epoch 14/20\n",
      "79/79 - 1s - 15ms/step - loss: 0.0251 - mae: 0.1114\n",
      "Epoch 15/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0242 - mae: 0.1108\n",
      "Epoch 16/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0326 - mae: 0.1260\n",
      "Epoch 17/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0246 - mae: 0.1099\n",
      "Epoch 18/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0239 - mae: 0.1092\n",
      "Epoch 19/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0260 - mae: 0.1106\n",
      "Epoch 20/20\n",
      "79/79 - 1s - 14ms/step - loss: 0.0275 - mae: 0.1192\n",
      "Model 3 saved as '../models/EURUSD_daily/lstm_model_full_3.keras'.\n"
     ]
    }
   ],
   "source": [
    "# Retrain and save models\n",
    "best_params_1 = {'num_layers': 3, 'units_0': 64, 'dropout_0': 0.1, 'lr': 0.007527178255464862, 'units_1': 128, 'dropout_1': 0.1, 'units_2': 32, 'dropout_2': 0.1}\n",
    "best_params_2 = {'num_layers': 2, 'units_0': 64, 'dropout_0': 0.2, 'lr': 0.006641024661942141, 'units_1': 32, 'dropout_1': 0.2, 'units_2': 64, 'dropout_2': 0.1}\n",
    "best_params_3 = {'num_layers': 2, 'units_0': 32, 'dropout_0': 0.30000000000000004, 'lr': 0.009043644296402382, 'units_1': 64, 'dropout_1': 0.4, 'units_2': 64, 'dropout_2': 0.2}\n",
    "\n",
    "\n",
    "model_nums = []\n",
    "for i, params in enumerate([best_params_1, best_params_2, best_params_3], start=1):\n",
    "    print(f\"Training Model {i} with params: {params}\")\n",
    "    \n",
    "    # Build the model using the selected hyperparameters\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_full.shape[1], X_full.shape[2])))\n",
    "\n",
    "    # Add LSTM layers based on the params\n",
    "    for layer in range(params['num_layers']):\n",
    "        return_sequences = layer < (params['num_layers'] - 1)\n",
    "        model.add(LSTM(params[f'units_{layer}'], return_sequences=return_sequences))\n",
    "        model.add(Dropout(params[f'dropout_{layer}']))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=params['lr']),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Train the model on the full dataset\n",
    "    model.fit(\n",
    "        X_full, y_full,\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        verbose=2,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5)]\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"../models/EURUSD_daily/lstm_model_full_{i}.keras\"\n",
    "    model.save(model_path)\n",
    "    model_nums.append(i)\n",
    "    print(f\"Model {i} saved as '{model_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d511e33-6b88-4c25-a534-ca7a485cad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model 1 successfully from '../models/EURUSD_daily/lstm_model_full_1.h5'\n",
      "Loaded Model 2 successfully from '../models/EURUSD_daily/lstm_model_full_2.h5'\n",
      "Loaded Model 3 successfully from '../models/EURUSD_daily/lstm_model_full_3.h5'\n"
     ]
    }
   ],
   "source": [
    "# Verify saved models\n",
    "for i in model_nums:\n",
    "    model_path = f\"../models/EURUSD_daily/lstm_model_full_{i}.h5\"\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Loaded Model {i} successfully from '{model_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
